# Ollama API Configuration
# Default: http://localhost:11434
# Can be used with regular Ollama or Ollama Turbo API Proxy
OLLAMA_API_URL=http://localhost:11434
# Optional: Ollama API Key (for Ollama Turbo cloud service)
# OLLAMA_API_KEY=your_ollama_api_key_here

# Meta Llama API Configuration (Optional)
# For using official Meta Llama models via api.llama.com
# Note: API is currently in preview - join waitlist for access
# LLAMA_API_URL=https://api.llama.com/v1
# LLAMA_API_KEY=your_meta_llama_api_key_here

# MongoDB Connection (optional - for saving projects)
MONGODB_URI=mongodb://localhost:27017/deepsite

# Rate limiting per IP address
MAX_REQUESTS_PER_IP=100

# Cloudflare Pages Configuration (for *.9gent.com subdomain deployment)
# CLOUDFLARE_ACCOUNT_ID=your_cloudflare_account_id_here
# CLOUDFLARE_API_TOKEN=your_cloudflare_api_token_here